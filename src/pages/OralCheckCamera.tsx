import React, { useEffect, useRef, useState } from "react";
import {
  Box,
  Button,
  Flex,
  Heading,
  Image,
  Text,
  useToast,
} from "@chakra-ui/react";

const OralCheckCamera: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const [photo, setPhoto] = useState<string | null>(null);
  const [facingMode, setFacingMode] = useState<"user" | "environment">("user");
  const toast = useToast();

  // âœ… PC / ëª¨ë°”ì¼ ìë™ ê°ì§€
  const getDefaultFacingMode = (): "user" | "environment" => {
    const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
    return isMobile ? "environment" : "user";
  };

  // âœ… ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = async (mode: "user" | "environment") => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: mode },
        audio: false,
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    } catch (err: unknown) {
      toast({
        title: "ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨",
        description: err instanceof Error ? err.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜",
        status: "error",
        duration: 3000,
      });
    }
  };

  // âœ… ì „ë©´/í›„ë©´ ì¹´ë©”ë¼ ì „í™˜
  const handleSwitchCamera = () => {
    const newMode = facingMode === "user" ? "environment" : "user";
    setFacingMode(newMode);
    startCamera(newMode);
  };

  // âœ… ì´¬ì˜
  const handleCapture = () => {
    if (!canvasRef.current || !videoRef.current) return;
    const canvas = canvasRef.current;
    const video = videoRef.current;
    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    const dataUrl = canvas.toDataURL("image/png");
    setPhoto(dataUrl);
  };

  // âœ… ìµœì´ˆ ì‹¤í–‰ ì‹œ ì¹´ë©”ë¼ ì‹œì‘
  useEffect(() => {
    const defaultMode = getDefaultFacingMode();
    setFacingMode(defaultMode);
    startCamera(defaultMode);

    return () => {
      if (videoRef.current?.srcObject) {
        const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
        tracks.forEach((track) => track.stop());
      }
    };
  }, []);

  return (
    <Flex direction="column" align="center" p={6}>
      <Heading size="md" mb={4}>
        êµ¬ê°• ì´¬ì˜í•˜ê¸°
      </Heading>

      {/* ì¹´ë©”ë¼ í™”ë©´ */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        style={{
          width: "100%",
          maxWidth: "350px",
          borderRadius: "12px",
          border: "2px solid #ddd",
          marginBottom: "12px",
        }}
      />

      {/* ë²„íŠ¼ */}
      <Flex gap={3} mb={4}>
        <Button onClick={handleSwitchCamera} colorScheme="teal" size="sm">
          ğŸ”„ ì¹´ë©”ë¼ ì „í™˜
        </Button>
        <Button onClick={handleCapture} colorScheme="blue" size="sm">
          ğŸ“¸ ì´¬ì˜í•˜ê¸°
        </Button>
      </Flex>

      {/* ì´¬ì˜ëœ ì´ë¯¸ì§€ */}
      {photo && (
        <Box textAlign="center">
          <Text fontSize="sm" mb={2}>
            ì´¬ì˜ëœ ì´ë¯¸ì§€
          </Text>
          <Image
            src={photo}
            alt="Captured"
            borderRadius="md"
            maxW="300px"
            mx="auto"
          />
        </Box>
      )}

      {/* ìˆ¨ê¹€ ìº”ë²„ìŠ¤ */}
      <canvas ref={canvasRef} style={{ display: "none" }} />
    </Flex>
  );
};

export default OralCheckCamera;
